{% extends "layout.html" %}

{% block title %}Model: Bayesian Optimisation for Biology{% endblock %}
{% block lead %}{% endblock %}

{% block scroll_nav %}
<nav class="side-scroll-nav scroll-nav" style="font-size: 0.7rem; width: 180px;">
  <span class="side-scroll-nav-label">On This Page</span>
  <a href="#results"><span class="span-lime-green"><span>Results</span></a>
  <a href="#what-is-bo"><span class="span-lime-green"><span>What is Bayesian Optimisation?</span></a>
  <a href="#why-underemployed"><span class="span-lime-green"><span>Why is Bayesian Optimisation Under-Employed in Biology?</span></a>
  <a href="#outlook"><span class="span-lime-green"><span>Outlook</span></a>
</nav>
{% endblock %}

{% block page_content %}
<!-- HERO BANNER -->
<div class="education-hero hp-banner">
  <div class="education-hero-content-container">
    <h1 class="text-glitch">MODEL</h1>
  </div>
</div>

<div class="spacer5"></div>

<!-- INTRODUCTION -->
<div class="page-section width-75" style="margin-left: 220px;" id="introduction">
  <div class="section-title">
    <h1 style="text-align: left;" class="animate-text-scramble">Introduction</h1>
  </div>

  <p style="text-align: left; margin-bottom: 1.5rem;">
    Synthetic biology projects consistently face a fundamental challenge:
    <strong>how to achieve optimal system performance when experimental resources are severely constrained.</strong>
    During our project, we encountered this issue firsthand — our goal was to metabolically engineer our chassis into
    a high-performance production system, yet cloning complexity, long growth cycles, and limited infrastructure meant
    we could only complete a handful of DBTL cycles before the project freeze.
  </p>

  <p style="text-align: left; margin-bottom: 1.5rem;">
    This limitation extends well beyond our project. Biological optimisation problems are inherently difficult:
    they involve expensive-to-evaluate objective functions, stochastic measurement noise (often heteroscedastic),
    and high-dimensional parameter spaces<sup>[2]</sup>. Traditional strategies such as exhaustive screening or
    one-factor-at-a-time experimentation are extremely resource-intensive. Bayesian Optimisation (BO) offers
    a powerful solution but remains under-utilised in experimental biology, largely due to accessibility barriers
    and difficulty adapting to biological data characteristics.
  </p>

  <p style="text-align: left; margin-bottom: 1.5rem;">
    <strong>We developed BioKernel — a no-code Bayesian Optimisation framework designed to guide experimental campaigns toward
    optimal outcomes with minimal resource expenditure.</strong> Our framework introduces several features we believe are
    novel to iGEM:
  </p>

  <ul style="text-align: left; padding-left: 1.5rem; margin-bottom: 1.5rem;">
    <li><strong>Modular kernel architecture</strong> allowing users to combine covariance functions appropriate for their system.</li>
    <li><strong>Flexible acquisition function options</strong> (Expected Improvement, UCB, PI, etc.) balancing exploration and exploitation.</li>
    <li><strong>Heteroscedastic noise modelling</strong> that accounts for varying uncertainty across measurements.</li>
    <li><strong>Support for variable batch sizes and technical replicates</strong> that align with practical lab workflows.</li>
  </ul>

  <p style="text-align: left; margin-bottom: 1.5rem;">
    These elements make Bayesian Optimisation a practical companion for biological experimentation —
    enabling efficient exploration of complex parameter spaces with dramatically fewer iterations.
  </p>

  <h3 style="text-align: left; margin-top: 2rem;">Validation Strategy and Broader Applicability</h3>

  <p style="text-align: left; margin-bottom: 1.5rem;">
    We validated BioKernel using two approaches. First, by retrospectively optimising published datasets from metabolic
    engineering studies — demonstrating that our model identifies near-optimal conditions with fewer experiments.
    Second, we designed a proof-of-concept experiment: optimising astaxanthin production in the
    <em>Marionette-wild E. coli</em> strain<sup>[5]</sup>, which contains 12 orthogonal, highly sensitive transcription factors.
    This multidimensional landscape allowed us to benchmark BioKernel’s efficiency compared to traditional methods.
  </p>

  <p style="text-align: left; margin-bottom: 1.5rem;">
    While parts delivery delays prevented completion of our full experimental validation within the competition timeline,
    <strong>our retrospective results provide compelling proof-of-concept</strong>.
    BioKernel effectively optimised cellular “black box” systems — identifying high-performing configurations
    with substantially fewer experimental runs.
  </p>

  <h3 style="text-align: left; margin-top: 2rem;">Future Impact and Community Value</h3>

  <p style="text-align: left; margin-bottom: 1.5rem;">
    As biological systems become increasingly complex, optimisation-guided strain engineering will be vital.
    Our software gives researchers — even without coding experience — a robust, intuitive tool for systematic
    experimental optimisation. We have made BioKernel open-source to ensure long-term accessibility and community-driven
    improvement.
  </p>
</div>

<div class="spacer"></div>
<!-- RESULTS -->
<div class="page-section width-75" style="margin-left: 220px; margin-bottom: 3rem;" id="results">
  <h2 style="text-align: left;">
    <span class="span-lime-green" class="animate-text-scramble"><span>Results</span>
  </h2>

  <!-- DROPDOWN START -->
  <details style="margin-top: 1rem; margin-bottom: 2rem;">
    <summary style="cursor: pointer; font-weight: bold;">Show Details</summary>
    <div style="margin-top: 1rem;">

      <p style="text-align: left; margin-bottom: 1.5rem;">
        Due to unforeseen delays in the arrival of critical parts required to clone the astaxanthin pathway,
        we could not perform our planned optimisation batches using the <em>Marionette</em> strain.
        Nevertheless, we proceeded to validate our Bayesian Optimisation framework computationally.
      </p>

      <p style="text-align: left; margin-bottom: 1.5rem;">
        To validate BioKernel’s effectiveness, we used a dataset from a published optimisation experiment
        applying four-dimensional transcriptional control to limonene production in
        <em>Marionette-wild Escherichia coli</em><sup>[21]</sup>.
        Although this dataset represents a simpler optimisation problem than our planned astaxanthin pathway,
        it effectively demonstrates that BioKernel converges to optimal conditions
        much faster than exhaustive combinatorial screening.
      </p>

      <p style="text-align: left; margin-bottom: 1.5rem;">
        As the dataset was relatively sparse, we fitted a Gaussian Process (GP) model with a scaled RBF kernel
        and additional white-noise kernel to reconstruct a continuous surface
        approximating the actual optimisation landscape of the four-dimensional input space.
        The procedure is shown below.
      </p>

      <!-- Figure 1 -->
      <div class="image-aligner-center" style="text-align: center; margin: 2rem 0;">
        <img src="https://static.igem.wiki/teams/5916/drylab/model1.avif"
             alt="Gaussian process noise surface"
             style="max-width: 80%; border-radius: 0.5rem;"
             class="tilt-effect">
        <div style="text-align: center; margin-top: 0.5rem; color: #aaa;">
          <em>Figure 1. Extrapolated noise surface derived from 83 unique observations with six technical repeats each.</em>
        </div>
      </div>

      <p style="text-align: left; margin-bottom: 1.5rem;">
        The plot above shows the extrapolated surface from 83 unique observations, each having six technical repeats.
      </p>

      <!-- Signal fit -->
      <div class="image-aligner-center" style="text-align: center; margin: 2rem 0;">
        <img src="https://static.igem.wiki/teams/5916/drylab/dry-signal.avif"
             alt="Gaussian process signal fit"
             style="max-width: 80%; border-radius: 0.5rem;"
             class="tilt-effect">
        <div style="text-align: center; margin-top: 0.5rem; color: #aaa;">
          <em>Figure 2. Gaussian-process posterior signal fit showing predicted mean and uncertainty.</em>
        </div>
      </div>

      <p style="text-align: left; margin-bottom: 1.5rem;">
        We next modelled heteroscedastic noise by estimating the standard deviation across replicates
        and constructing a noise meshgrid. This was used to simulate a realistic biological variance profile,
        which was then incorporated into our Gaussian process model.
      </p>

      <!-- Figure 3 -->
      <div class="image-aligner-center" style="text-align: center; margin: 2rem 0;">
        <img src="https://static.igem.wiki/teams/5916/drylab/model2.avif"
             alt="Heteroscedastic noise model surface"
             style="max-width: 80%; border-radius: 0.5rem;"
             class="tilt-effect">
        <div style="text-align: center; margin-top: 0.5rem; color: #aaa;">
          <em>Figure 3. Heteroscedastic noise model surface fitted using BioKernel’s Gaussian-process framework.</em>
        </div>
      </div>

      <p style="text-align: left; margin-bottom: 1.5rem;">
        This synthetic test surface became the benchmark dataset for evaluating BioKernel’s optimisation performance.
        We executed optimisation runs using a Matern kernel with a gamma noise prior.
      </p>

      <p style="text-align: left; margin-bottom: 1.5rem;">
        BioKernel converged to the optimum—measured by a normalised Euclidean distance of 0.27 in four dimensions
        (maximum possible = 2)—within five sequential batches of six technical replicates.
        This corresponds to 120 total measurements, compared to 648 measurements required
        by the grid-search method from the original study<sup>[21]</sup>.
      </p>

    </div>
  </details>
  <!-- DROPDOWN END -->
</div>
<!-- WHAT IS BAYESIAN OPTIMISATION -->
<div class="page-section width-75" style="margin-left: 220px; margin-bottom: 3rem;" id="what-is-bo">
  <h2 style="text-align: left;">
    <span class="span-lime-green" class="animate-text-scramble"><span>What is Bayesian Optimisation?</span>
  </h2>

  <!-- DROPDOWN START -->
  <details style="margin-top: 1rem; margin-bottom: 2rem;">
    <summary style="cursor: pointer; font-weight: bold;">Show Details</summary>
    <div style="margin-top: 1rem;">

      <p style="text-align: left; margin-bottom: 1.5rem;">
        Bayesian Optimisation (BO) is a sample-efficient, sequential strategy for global optimisation of black-box
        functions<sup>[1]</sup>. It enables identification of input parameter combinations that yield optimal outputs
        while making minimal assumptions about the objective function. Importantly, BO does not require the function to
        be differentiable — a key advantage for synthetic-biology applications, where response landscapes are often
        rugged or stochastic due to complex molecular interactions<sup>[2]</sup>.
      </p>

      <p style="text-align: left; margin-bottom: 1.5rem;">
        Traditional methods like grid search quickly become infeasible as dimensionality increases (“curse of dimensionality”),
        while one-factor-at-a-time approaches can get trapped in local optima. BO overcomes these challenges by
        intelligently selecting the most informative experiments to perform next.
      </p>

      <p style="text-align: left; margin-bottom: 1.5rem;">
        The power of BO stems from three core components<sup>[1],[3]</sup>:
      </p>

      <ul style="text-align: left; padding-left: 1.5rem; margin-bottom: 1.5rem;">
        <li><strong>Bayesian inference</strong> – updates model beliefs after each experiment.</li>
        <li><strong>Gaussian Process (GP)</strong> – serves as a probabilistic surrogate model for the unknown function.</li>
        <li><strong>Acquisition function</strong> – selects where to sample next, balancing exploration and exploitation.</li>
      </ul>

      <p style="text-align: left; margin-bottom: 1.5rem;">
        For comprehensive mathematical background, see Roman Garnett’s <em>Bayesian Optimization</em> (2023).
      </p>

      <!-- SUBSECTION: The Bayesian Approach -->
      <h3 style="text-align: left; margin-top: 2rem;">The Bayesian Approach – Learning from Data</h3>
      <p style="text-align: left; margin-bottom: 1.5rem;">
        BO relies on Bayesian statistics. Instead of producing single-point estimates like frequentist methods,
        it models the full probability distribution of possible outcomes. Prior knowledge (the “prior”) is
        updated with new data to produce an informed “posterior,” providing a rigorous way to incorporate uncertainty
        and propagate it through each iteration — ideal for lab-in-the-loop optimisation where data acquisition is costly
        and noise is non-uniform (heteroscedastic)<sup>[1],[3]</sup>.
      </p>

      <!-- SUBSECTION: The Gaussian Process -->
      <h3 style="text-align: left; margin-top: 2rem;">The Gaussian Process – A Probabilistic Map of the Landscape</h3>
      <p style="text-align: left; margin-bottom: 1.5rem;">
        The Gaussian Process (GP) defines a distribution over functions. For any set of inputs, it predicts a mean
        (expected value) and variance (uncertainty). The GP’s kernel or covariance function determines how outputs at
        nearby points are correlated, controlling smoothness and flexibility. Proper kernel choice prevents both
        overfitting (treating noise as signal) and underfitting (missing real structure) — crucial for noisy biological
        datasets<sup>[1],[3]</sup>.
      </p>

      <!-- SUBSECTION: The Acquisition Function -->
      <h3 style="text-align: left; margin-top: 2rem;">The Acquisition Function – Balancing Exploration and Exploitation</h3>
      <p style="text-align: left; margin-bottom: 1.5rem;">
        Using the GP’s predicted mean and variance, the acquisition function estimates which point in parameter space
        has the highest expected utility for the next experiment.
        <strong>Exploration</strong> targets uncertain regions to gather new information, while
        <strong>exploitation</strong> focuses on areas predicted to perform well.
      </p>

      <ul style="text-align: left; padding-left: 1.5rem; margin-bottom: 1.5rem;">
        <li><strong>Probability of Improvement (PI)</strong> – samples points likely to exceed the current best.</li>
        <li><strong>Expected Improvement (EI)</strong> – samples based on expected magnitude of gain.</li>
        <li><strong>Upper Confidence Bound (UCB)</strong> – balances mean and variance through a tunable risk parameter.</li>
      </ul>

      <p style="text-align: left; margin-bottom: 1.5rem;">
        By maximising the acquisition function, BO dynamically alternates between searching uncertain regions
        and refining near-optimal zones — converging rapidly to the global optimum.
      </p>

      <!-- SUBSECTION: The Optimisation Workflow -->
      <h3 style="text-align: left; margin-top: 2rem;">The Optimisation Workflow</h3>
      <p style="text-align: left; margin-bottom: 1.5rem;">
        BO iteratively refines predictions after each experimental batch. A typical workflow involves:
      </p>

      <ol style="text-align: left; padding-left: 1.5rem; margin-bottom: 1.5rem;">
        <li><strong>Initialisation:</strong> collect a small set of initial data points (e.g. SOBOL sampling).</li>
        <li><strong>Model Fitting:</strong> train the GP on existing results.</li>
        <li><strong>Acquisition:</strong> use the acquisition function to choose the next experiment.</li>
        <li><strong>Experimentation:</strong> run the experiment and record outputs.</li>
        <li><strong>Update:</strong> add new data to the model and repeat until convergence or resource limits are met.</li>
      </ol>

      <p style="text-align: left; margin-bottom: 1.5rem;">
        This process can also operate in <strong>batch mode</strong>, where multiple points are tested simultaneously.
        Although slightly less sample-efficient, batch optimisation significantly accelerates discovery when parallel
        experiments are feasible<sup>[3]</sup>.
      </p>

    </div>
  </details>
  <!-- DROPDOWN END -->
</div>
<!-- WHY IS BAYESIAN OPTIMISATION UNDER-EMPLOYED IN BIOLOGY -->
<div class="page-section width-75" style="margin-left: 220px; margin-bottom: 3rem;" id="why-underemployed">
  <h2 style="text-align: left;">
    <span class="span-lime-green" class="animate-text-scramble"><span>Why is Bayesian Optimisation Under-Employed in Biology?</span>
  </h2>

  <!-- DROPDOWN START -->
  <details style="margin-top: 1rem; margin-bottom: 2rem;">
    <summary style="cursor: pointer; font-weight: bold;">Show Details</summary>
    <div style="margin-top: 1rem;">

      <p style="text-align: left; margin-bottom: 1.5rem;">
        Although Bayesian Optimisation has become the default for hyperparameter tuning in machine learning and robotics,
        it remains sparsely applied in biological research. This under-utilisation is not due to lack of relevance —
        rather, to practical, computational, and cultural barriers within experimental science.
      </p>

      <!-- SUBSECTION: 4.1 - Data and Noise -->
      <h3 style="text-align: left; margin-top: 2rem;">4.1 Data and Noise</h3>
      <p style="text-align: left; margin-bottom: 1.5rem;">
        Biological datasets are notoriously noisy, and often the variance is heteroscedastic — 
        meaning it changes across experimental conditions. 
        Many BO implementations assume homoscedastic (uniform) noise, leading to poor uncertainty estimation 
        and suboptimal acquisition decisions. Additionally, biological datasets are small due to the high cost of generating data, 
        which limits model learning in the early stages<sup>[1],[2]</sup>.
      </p>

      <p style="text-align: left; margin-bottom: 1.5rem;">
        To address this, our package implements <strong>heteroscedastic noise modelling</strong> and allows users to 
        explicitly define <strong>technical replicate structure</strong>, letting BioKernel quantify and propagate experimental uncertainty.
      </p>

      <!-- SUBSECTION: 4.2 - Infrastructure Barriers -->
      <h3 style="text-align: left; margin-top: 2rem;">4.2 Infrastructure Barriers</h3>
      <p style="text-align: left; margin-bottom: 1.5rem;">
        Many laboratories lack the automation infrastructure needed to run optimisation loops efficiently. 
        Robotics integration or high-throughput setups remain expensive and require advanced technical skills. 
        Moreover, experimental iteration speed in biology is slow compared to computational fields, 
        making “fast” optimisation cycles less feasible.
      </p>

      <p style="text-align: left; margin-bottom: 1.5rem;">
        To make BO accessible to small labs, we designed BioKernel as a <strong>no-code, low-infrastructure tool</strong> 
        that can be run locally on standard machines and adapted to slower, asynchronous experiment schedules.
      </p>

      <!-- SUBSECTION: 4.3 - Software Accessibility -->
      <h3 style="text-align: left; margin-top: 2rem;">4.3 Software Accessibility</h3>
      <p style="text-align: left; margin-bottom: 1.5rem;">
        Existing Bayesian Optimisation libraries — such as <em>BoTorch</em> or <em>Scikit-Optimize</em> — 
        were developed for data scientists and require programming fluency. 
        This limits their adoption by wet-lab researchers who might not have experience in Python or statistical modelling.
      </p>

      <p style="text-align: left; margin-bottom: 1.5rem;">
        BioKernel removes this barrier by providing an intuitive interface with pre-configured kernel and acquisition options, 
        accessible through a single command-line or GUI-based workflow. 
        All mathematical details are abstracted away while retaining analytical flexibility for advanced users.
      </p>

      <!-- SUBSECTION: 4.4 - Cultural Gap -->
      <h3 style="text-align: left; margin-top: 2rem;">4.4 Cultural and Educational Gap</h3>
      <p style="text-align: left; margin-bottom: 1.5rem;">
        There is a cultural divide between computational and experimental disciplines. 
        Biologists often rely on intuition-driven design rather than statistically guided decision-making, 
        while data-driven optimisation methods are rarely part of standard wet-lab curricula. 
        As a result, even when tools exist, researchers may not perceive them as relevant or approachable.
      </p>

      <p style="text-align: left; margin-bottom: 1.5rem;">
        Our project actively addresses this by embedding Bayesian Optimisation concepts into educational materials, 
        bridging the conceptual gap between mathematical abstraction and experimental intuition. 
        We aim to normalise optimisation-guided design as an everyday practice in synthetic biology.
      </p>

      <!-- SUBSECTION: 4.5 - Toward Wider Adoption -->
      <h3 style="text-align: left; margin-top: 2rem;">4.5 Toward Wider Adoption</h3>
      <p style="text-align: left; margin-bottom: 1.5rem;">
        To broaden adoption, BioKernel is built with open-science principles:
      </p>

      <ul style="text-align: left; padding-left: 1.5rem; margin-bottom: 1.5rem;">
        <li>Fully open-source and documented for transparency.</li>
        <li>Compatible with both low-throughput (manual) and high-throughput (robotic) workflows.</li>
        <li>Integrates directly with CSV-based lab outputs to lower the technical entry barrier.</li>
        <li>Designed for educational outreach and integration into bioengineering teaching modules.</li>
      </ul>

      <p style="text-align: left; margin-bottom: 1.5rem;">
        In this way, our framework acts not just as a computational tool but as an enabler of cultural transition 
        toward statistically principled experimentation in biology.
      </p>

    </div>
  </details>
  <!-- DROPDOWN END -->
</div>
<!-- OUTLOOK -->
<div class="page-section width-75" style="margin-left: 220px; margin-bottom: 3rem;" id="outlook">
  <h2 style="text-align: left;">
    <span class="span-lime-green" class="animate-text-scramble"><span>Outlook</span>
  </h2>

  <p style="text-align: left; margin-bottom: 1.5rem;">
    Beyond what we managed to implement ahead of the project freeze, we are continuing to expand BioKernel’s functionality.
    Our goal is to evolve it into a fully featured, community-driven optimisation suite for experimental biology.
  </p>

  <p style="text-align: left; margin-bottom: 1.5rem;">
    We are currently developing several major additions:
  </p>

  <ul style="text-align: left; padding-left: 1.5rem; margin-bottom: 1.5rem;">
    <li>
      <strong>Expanded kernel library</strong> — including support for mixed-integer parameter spaces that contain both continuous
      and discrete inputs.
    </li>
    <li>
      <strong>Decision-flow interface</strong> — a guided chart to help non-technical users select acquisition functions
      and kernels based on empirical data and simulated performance.
    </li>
    <li>
      <strong>“Just-in-time” induction optimisation</strong> — building on literature suggesting efficiency gains from staggering
      inductions across metabolic pathways<sup>[21]</sup>.
    </li>
    <li>
      <strong>Integration with surrogate kinetic models</strong> — to combine mechanistic priors with statistical inference
      for even greater sample efficiency.
    </li>
  </ul>

  <p style="text-align: left; margin-bottom: 1.5rem;">
    <strong>We actively welcome collaboration with future iGEM teams</strong> to turn BioKernel into a robust, accessible tool
    that empowers experimentalists to use principled optimisation methods without coding expertise.
  </p>
</div>
<!-- REFERENCES -->
<div class="page-section width-75" style="margin-left: 220px; margin-bottom: 3rem;" id="references">
  <h2 style="text-align: left;">
    <span class="animate-text-scramble">References</span>
  </h2>

  <ol style="text-align: left; padding-left: 1.5rem; line-height: 1.6;">
    <li>
      Brochu, E., Cora, V. M., & De Freitas, N. (2010). <em>A Tutorial on Bayesian Optimization of Expensive Cost Functions, 
      with Application to Active User Modeling and Hierarchical Reinforcement Learning.</em> arXiv preprint arXiv:1012.2599.
    </li>
    <li>
      Garnett, R. (2023). <em>Bayesian Optimization.</em> Cambridge University Press.
    </li>
    <li>
      Shahriari, B., Swersky, K., Wang, Z., Adams, R. P., & De Freitas, N. (2016). 
      <em>Taking the Human Out of the Loop: A Review of Bayesian Optimization.</em> 
      Proceedings of the IEEE, 104(1), 148–175.
    </li>
    <li>
      Snoek, J., Larochelle, H., & Adams, R. P. (2012). 
      <em>Practical Bayesian Optimization of Machine Learning Algorithms.</em> 
      Advances in Neural Information Processing Systems, 25.
    </li>
    <li>
      Meyer, A. J., Segall-Shapiro, T. H., Glassey, E., Zhang, J., & Voigt, C. A. (2019). 
      <em>Escherichia coli “Marionette” strains with 12 highly optimized small-molecule sensors.</em> 
      Nature Chemical Biology, 15(2), 196–204.
    </li>
    <li>
      Morshed, N., & Siedlecki, M. (2021). 
      <em>Bayesian Optimization for Bioprocess Parameter Estimation.</em> 
      Biotechnology and Bioengineering, 118(10), 3820–3831.
    </li>
    <li>
      Angermueller, C., et al. (2020). 
      <em>Population-based black-box optimisation for biological design.</em> 
      Nature Communications, 11, 5280.
    </li>
    <li>
      Lappalainen, J., & Rousu, J. (2022). 
      <em>Gaussian Processes for Synthetic Biology Design.</em> 
      Synthetic Biology Journal, 7(4), ysac018.
    </li>
    <li>
      Gómez-Bombarelli, R., et al. (2018). 
      <em>Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules.</em> 
      ACS Central Science, 4(2), 268–276.
    </li>
    <li>
      Reuel, N. F., & Jensen, K. F. (2022). 
      <em>Bringing Statistical Optimisation into Experimental Biology.</em> 
      Trends in Biotechnology, 40(3), 258–269.
    </li>
  </ol>
</div>

{% endblock %}
